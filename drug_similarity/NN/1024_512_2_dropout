import tensorflow as tf
import numpy as np
sess = tf.InteractiveSession()

#Plugging in the x and y datasets
x = tf.placeholder("float", [None, 1024])
y = tf.placeholder("float", [None, 2 ] )

#Defining weight variables
def weight_variable(shape):
  initial = tf.truncated_normal(shape, stddev=0.1)
  return tf.Variable(initial)
  
def bias_variable(shape):
  initial = tf.constant(0.1, shape=shape)
  return tf.Variable(initial)
  
#First Layer (512 Nodes)
w_l1=weight_variable([1024,512])
b_l1=bias_variable([512])
h_1=tf.nn.relu(tf.matmul(x,w_l1) + b_l1)

#Dropout
keep_prob = tf.placeholder("float")
h_1_drop = tf.nn.dropout(h_1, keep_prob)

#Readout Layer (Binary output)
w_l2=weight_variable([512,2])
b_l2=bias_variable([2])
y_model=tf.nn.softmax(tf.matmul(h_1_drop,w_l2) + b_l2)

#Training the model
#cross_entropy = -tf.reduce_sum(y*tf.log(y_model))
loss = tf.reduce_mean(tf.square(y - y_model))
train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)
correct_prediction = tf.equal(tf.argmax(y_model,1), tf.argmax(y,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))

#Running the iterations
sess.run(tf.initialize_all_variables())
for i in range(100000):
  sess.run(train_step, feed_dict={x: x_data, y: y_data,,keep_prob: 0.5})
  print sess.run(w_l3[0,:])
  
  
print sess.run(accuracy, feed_dict={x: x_data, y: y_data, keep_prob: 1.0})
